# -*- coding: utf-8 -*-
"""Airbnb_Hotel_Booking_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17TUqO5vwL91Wzag8gMYiZgFHz7cHUJy_

# Airbnb Hotel Booking Analysis üè†
### VOIS Project - Data Analysis and Insights

## About the Project
Airbnb has transformed the hospitality industry by offering a platform that connects travelers with unique lodging experiences around the world. This comprehensive analysis delves into the New York City Airbnb dataset to extract meaningful insights through rigorous data cleaning, exploratory analysis, and visualization techniques.

## Learning Objectives
By the end of this analysis, we will:
- **Identify and Analyze Booking Trends**: Determine peak booking patterns and variations by location
- **Evaluate Pricing Strategies**: Analyze effective pricing strategies and their impact on booking rates
- **Understand Guest Preferences**: Identify the most desired amenities and features
- **Assess Host Performance**: Identify practices of high performing hosts
- **Provide Data-Driven Recommendations**: Deliver actionable insights for hosts and platform optimization

## Research Questions
This project aims to uncover insights from the Airbnb Open Data by answering:
1. What are the different property types in the Dataset?
2. Which neighborhood group has the highest number of listings?
3. Which neighborhoods group have the highest average prices for Airbnb listings?
4. Is there a relationship between the construction year of property and price?
5. Who are the top 10 hosts by calculated host listing count?
6. Are hosts with verified identities more likely to receive positive reviews?
7. Is there a correlation between the price of a listing and its service fee?
8. What is the average review rate number (e.g., stars) for listings, and does it vary based on neighborhood group and room type?
9. Are hosts with a higher calculated host listings count more likely to maintain higher availability throughout the year?

## 1. Data Loading and Initial Exploration
"""

# Import Required Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# Set style for better visualizations
plt.style.use('default')
sns.set_palette("husl")

print("üìö All libraries imported successfully!")
print("üöÄ Ready to analyze Airbnb data!")

# Load the Airbnb Dataset
try:
    df = pd.read_excel("/content/1730285881-Airbnb_Open_Data.xlsx")
    print("‚úÖ Dataset loaded successfully!")
    print(f"üìä Dataset shape: {df.shape}")
    print(f"üìã Columns: {df.shape[1]} | Rows: {df.shape[0]}")
except FileNotFoundError:
    print("‚ùå File not found. Please check the file path.")
except Exception as e:
    print(f"‚ùå Error loading file: {e}")

# Dataset Overview
print("üîç DATASET OVERVIEW")
print("="*50)
print(f"Shape: {df.shape}")
print(f"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
print("\nüìã Column Information:")
print("-"*30)
print(df.dtypes)

# Display first few rows
print("üëÄ First 5 rows of the dataset:")
print("="*50)
df.head()

# Basic statistical information
print("üìä Statistical Summary:")
print("="*50)
df.describe()

"""## 2. Data Cleaning and Preprocessing
Data wrangling is crucial for ensuring data quality and reliability. We'll handle missing values, duplicates, and format inconsistencies.
"""

# Check for missing values
print("üîç Missing Values Analysis:")
print("="*40)
missing_values = df.isnull().sum()
missing_percent = (df.isnull().sum() / len(df)) * 100

missing_df = pd.DataFrame({
    'Column': missing_values.index,
    'Missing Count': missing_values.values,
    'Missing Percentage': missing_percent.values
})

missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)
print(missing_df.to_string(index=False))

# Visualize missing values
plt.figure(figsize=(12, 6))
if not missing_df.empty:
    plt.subplot(1, 2, 1)
    sns.barplot(data=missing_df.head(10), y='Column', x='Missing Count', palette='viridis')
    plt.title('Top 10 Columns with Missing Values')
    plt.xlabel('Missing Count')

    plt.subplot(1, 2, 2)
    sns.barplot(data=missing_df.head(10), y='Column', x='Missing Percentage', palette='plasma')
    plt.title('Missing Values Percentage')
    plt.xlabel('Missing Percentage (%)')
else:
    plt.text(0.5, 0.5, 'üéâ No Missing Values Found!', fontsize=20, ha='center', va='center')

plt.tight_layout()
plt.show()

# Check for duplicates
print("üîç Duplicate Records Analysis:")
print("="*40)
duplicates = df.duplicated().sum()
print(f"Total duplicate rows: {duplicates}")
print(f"Percentage of duplicates: {(duplicates/len(df))*100:.2f}%")

if duplicates > 0:
    print(f"\nüßπ Removing {duplicates} duplicate rows...")
    df = df.drop_duplicates()
    print(f"‚úÖ Dataset shape after removing duplicates: {df.shape}")
else:
    print("‚úÖ No duplicate rows found!")

# Clean and standardize column names
print("üßπ Cleaning Column Names:")
print("="*30)

# Store original column names
original_columns = df.columns.tolist()

# Clean column names - remove special characters, spaces, and standardize
df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('[^a-zA-Z0-9_]', '', regex=True)

print("Column name changes:")
for old, new in zip(original_columns, df.columns):
    if old != new:
        print(f"  '{old}' ‚Üí '{new}'")

print(f"\n‚úÖ Cleaned column names: {list(df.columns)}")

"""## 3. Property Types Analysis
**Question 1: What are the different property types in the Dataset?**
"""

# Analyze property types
# Let's first check what columns might contain property type information
print("üè† Available columns for property analysis:")
print("="*45)
property_related_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['property', 'room', 'type', 'category'])]
print(f"Property-related columns: {property_related_cols}")

# Display all columns to understand the dataset structure better
print(f"\nAll columns in dataset: {list(df.columns)}")

# If we have property type or room type columns, analyze them
if property_related_cols:
    for col in property_related_cols:
        print(f"\nüìä Analysis of '{col}':")
        print("-" * 30)
        value_counts = df[col].value_counts()
        print(value_counts)

        # Create visualization for each property-related column
        plt.figure(figsize=(12, 6))

        plt.subplot(1, 2, 1)
        value_counts.plot(kind='bar', color='skyblue', edgecolor='black')
        plt.title(f'Distribution of {col.title()}')
        plt.xlabel(col.title())
        plt.ylabel('Count')
        plt.xticks(rotation=45)

        plt.subplot(1, 2, 2)
        plt.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%', startangle=90)
        plt.title(f'Percentage Distribution of {col.title()}')

        plt.tight_layout()
        plt.show()
else:
    print("‚ö†Ô∏è No specific property type columns found. Let's explore the dataset structure first.")

"""## 4. Neighborhood Group Analysis
**Question 2: Which neighborhood group has the highest number of listings?**
"""

# Analyze neighborhood groups
print("üèòÔ∏è Neighborhood Group Analysis:")
print("="*40)

# Find neighborhood-related columns
neighborhood_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['neighborhood', 'borough', 'area', 'district'])]
print(f"Neighborhood-related columns: {neighborhood_cols}")

if neighborhood_cols:
    # Analyze the main neighborhood column
    main_neighborhood_col = neighborhood_cols[0]  # Usually the first one is the main grouping

    neighborhood_counts = df[main_neighborhood_col].value_counts()
    print(f"\nüìä Number of listings by {main_neighborhood_col}:")
    print("-" * 40)
    print(neighborhood_counts)

    # Create comprehensive visualizations
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # Bar chart
    neighborhood_counts.plot(kind='bar', ax=axes[0,0], color='lightcoral', edgecolor='black')
    axes[0,0].set_title(f'Number of Listings by {main_neighborhood_col.title()}')
    axes[0,0].set_xlabel(main_neighborhood_col.title())
    axes[0,0].set_ylabel('Number of Listings')
    axes[0,0].tick_params(axis='x', rotation=45)

    # Horizontal bar chart for better readability
    neighborhood_counts.plot(kind='barh', ax=axes[0,1], color='lightblue', edgecolor='black')
    axes[0,1].set_title(f'Listings Count (Horizontal View)')
    axes[0,1].set_xlabel('Number of Listings')

    # Pie chart
    axes[1,0].pie(neighborhood_counts.values, labels=neighborhood_counts.index, autopct='%1.1f%%', startangle=90)
    axes[1,0].set_title(f'Percentage Distribution by {main_neighborhood_col.title()}')

    # Donut chart
    wedges, texts, autotexts = axes[1,1].pie(neighborhood_counts.values, labels=neighborhood_counts.index,
                                            autopct='%1.1f%%', startangle=90,
                                            wedgeprops=dict(width=0.5))
    axes[1,1].set_title(f'Donut Chart - {main_neighborhood_col.title()} Distribution')

    plt.tight_layout()
    plt.show()

    # Print insights
    max_neighborhood = neighborhood_counts.index[0]
    max_count = neighborhood_counts.iloc[0]
    print(f"\nüí° KEY INSIGHT:")
    print(f"üèÜ '{max_neighborhood}' has the highest number of listings with {max_count} properties")
    print(f"üìà This represents {(max_count/len(df))*100:.1f}% of all listings")

else:
    print("‚ö†Ô∏è No neighborhood-related columns found in the dataset.")

"""## 5. Pricing Analysis by Location
**Question 3: Which neighborhood group has the highest average prices for Airbnb listings?**
"""

# Analyze pricing by neighborhood
print("üí∞ Pricing Analysis by Neighborhood:")
print("="*40)

# Find price-related columns
price_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['price', 'cost', 'rate', 'fee'])]
print(f"Price-related columns: {price_cols}")

# Find neighborhood columns
neighborhood_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['neighborhood', 'borough', 'area', 'district'])]

if price_cols and neighborhood_cols:
    price_col = price_cols[0]  # Use the first price column
    neighborhood_col = neighborhood_cols[0]  # Use the first neighborhood column

    # Clean price data (remove $ signs, convert to numeric)
    if df[price_col].dtype == 'object':
        df[price_col] = pd.to_numeric(df[price_col].astype(str).str.replace('$', '').str.replace(',', ''), errors='coerce')

    # Remove outliers for better analysis (prices above 99th percentile or below 1st percentile)
    price_q99 = df[price_col].quantile(0.99)
    price_q01 = df[price_col].quantile(0.01)

    # Calculate average prices by neighborhood
    avg_prices = df.groupby(neighborhood_col)[price_col].agg(['mean', 'median', 'std', 'count']).round(2)
    avg_prices = avg_prices.sort_values('mean', ascending=False)

    print(f"\nüìä Average prices by {neighborhood_col}:")
    print("-" * 50)
    print(avg_prices)

    # Create comprehensive visualizations
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # Bar chart of average prices
    avg_prices['mean'].plot(kind='bar', ax=axes[0,0], color='gold', edgecolor='black')
    axes[0,0].set_title(f'Average Price by {neighborhood_col.title()}')
    axes[0,0].set_ylabel('Average Price ($)')
    axes[0,0].tick_params(axis='x', rotation=45)

    # Box plot showing price distribution
    df.boxplot(column=price_col, by=neighborhood_col, ax=axes[0,1])
    axes[0,1].set_title(f'Price Distribution by {neighborhood_col.title()}')
    axes[0,1].set_ylabel('Price ($)')
    plt.suptitle('')  # Remove default title

    # Horizontal bar chart for better readability
    avg_prices['mean'].plot(kind='barh', ax=axes[1,0], color='lightgreen', edgecolor='black')
    axes[1,0].set_title('Average Price (Horizontal View)')
    axes[1,0].set_xlabel('Average Price ($)')

    # Price range comparison (min, max, avg)
    price_stats = df.groupby(neighborhood_col)[price_col].agg(['min', 'mean', 'max'])
    price_stats.plot(kind='bar', ax=axes[1,1], width=0.8)
    axes[1,1].set_title('Price Range by Neighborhood (Min, Avg, Max)')
    axes[1,1].set_ylabel('Price ($)')
    axes[1,1].tick_params(axis='x', rotation=45)
    axes[1,1].legend(['Minimum', 'Average', 'Maximum'])

    plt.tight_layout()
    plt.show()

    # Interactive plotly visualization
    fig_plotly = px.bar(
        x=avg_prices.index,
        y=avg_prices['mean'],
        title=f'Average Airbnb Prices by {neighborhood_col.title()}',
        labels={'x': neighborhood_col.title(), 'y': 'Average Price ($)'},
        color=avg_prices['mean'],
        color_continuous_scale='Viridis'
    )
    fig_plotly.update_layout(xaxis_tickangle=-45)
    fig_plotly.show()

    # Print insights
    highest_price_neighborhood = avg_prices.index[0]
    highest_avg_price = avg_prices['mean'].iloc[0]
    lowest_price_neighborhood = avg_prices.index[-1]
    lowest_avg_price = avg_prices['mean'].iloc[-1]

    print(f"\nüí° KEY INSIGHTS:")
    print(f"üèÜ Highest average price: '{highest_price_neighborhood}' - ${highest_avg_price:.2f}")
    print(f"üí∞ Lowest average price: '{lowest_price_neighborhood}' - ${lowest_avg_price:.2f}")
    print(f"üìä Price difference: ${highest_avg_price - lowest_avg_price:.2f}")
    print(f"üìà Price ratio: {highest_avg_price/lowest_avg_price:.1f}x more expensive")

else:
    print("‚ö†Ô∏è Required columns (price and neighborhood) not found for this analysis.")

"""## 6. Property Construction Year vs Price Analysis
**Question 4: Is there a relationship between the construction year of property and price?**
"""

# Analyze relationship between construction year and price
print("üèóÔ∏è Construction Year vs Price Analysis:")
print("="*45)

# Find construction year related columns
year_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['year', 'built', 'construction', 'date'])]
print(f"Year-related columns: {year_cols}")

# Find price columns
price_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['price', 'cost', 'rate'])]

if year_cols and price_cols:
    year_col = year_cols[0]  # Use the first year column
    price_col = price_cols[0]  # Use the first price column

    # Clean the data
    df_clean = df[[year_col, price_col]].copy()

    # Clean year data
    if df_clean[year_col].dtype == 'object':
        df_clean[year_col] = pd.to_numeric(df_clean[year_col], errors='coerce')

    # Clean price data
    if df_clean[price_col].dtype == 'object':
        df_clean[price_col] = pd.to_numeric(df_clean[price_col].astype(str).str.replace('$', '').str.replace(',', ''), errors='coerce')

    # Remove missing values and outliers
    df_clean = df_clean.dropna()

    # Filter reasonable years (e.g., 1800-2024)
    df_clean = df_clean[(df_clean[year_col] >= 1800) & (df_clean[year_col] <= 2024)]

    # Remove price outliers (keep data within 1st and 99th percentile)
    price_q01 = df_clean[price_col].quantile(0.01)
    price_q99 = df_clean[price_col].quantile(0.99)
    df_clean = df_clean[(df_clean[price_col] >= price_q01) & (df_clean[price_col] <= price_q99)]

    if len(df_clean) > 0:
        # Calculate correlation
        correlation = df_clean[year_col].corr(df_clean[price_col])

        print(f"\nüìä Correlation Analysis:")
        print(f"Sample size: {len(df_clean)} properties")
        print(f"Correlation coefficient: {correlation:.4f}")

        # Interpret correlation strength
        if abs(correlation) < 0.1:
            strength = "Very weak"
        elif abs(correlation) < 0.3:
            strength = "Weak"
        elif abs(correlation) < 0.5:
            strength = "Moderate"
        elif abs(correlation) < 0.7:
            strength = "Strong"
        else:
            strength = "Very strong"

        direction = "positive" if correlation > 0 else "negative"
        print(f"Relationship strength: {strength} {direction} correlation")

        # Create comprehensive visualizations
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # Scatter plot
        axes[0,0].scatter(df_clean[year_col], df_clean[price_col], alpha=0.5, color='blue')
        axes[0,0].set_xlabel(f'{year_col.title()}')
        axes[0,0].set_ylabel(f'{price_col.title()} ($)')
        axes[0,0].set_title(f'Scatter Plot: {year_col.title()} vs {price_col.title()}')

        # Add trend line
        z = np.polyfit(df_clean[year_col], df_clean[price_col], 1)
        p = np.poly1d(z)
        axes[0,0].plot(df_clean[year_col], p(df_clean[year_col]), "r--", alpha=0.8, linewidth=2)

        # Hexbin plot for density
        axes[0,1].hexbin(df_clean[year_col], df_clean[price_col], gridsize=20, cmap='Blues')
        axes[0,1].set_xlabel(f'{year_col.title()}')
        axes[0,1].set_ylabel(f'{price_col.title()} ($)')
        axes[0,1].set_title('Density Plot: Construction Year vs Price')

        # Average price by decade
        df_clean['decade'] = (df_clean[year_col] // 10) * 10
        decade_prices = df_clean.groupby('decade')[price_col].mean()
        decade_prices.plot(kind='bar', ax=axes[1,0], color='green', edgecolor='black')
        axes[1,0].set_title('Average Price by Decade')
        axes[1,0].set_xlabel('Decade')
        axes[1,0].set_ylabel('Average Price ($)')
        axes[1,0].tick_params(axis='x', rotation=45)

        # Box plot by year groups
        year_bins = pd.cut(df_clean[year_col], bins=5, labels=['Very Old', 'Old', 'Medium', 'Recent', 'New'])
        df_clean['year_group'] = year_bins
        df_clean.boxplot(column=price_col, by='year_group', ax=axes[1,1])
        axes[1,1].set_title('Price Distribution by Property Age')
        axes[1,1].set_xlabel('Property Age Group')
        axes[1,1].set_ylabel('Price ($)')
        plt.suptitle('')  # Remove default title

        plt.tight_layout()
        plt.show()

        # Interactive plotly scatter plot
        fig_plotly = px.scatter(
            df_clean,
            x=year_col,
            y=price_col,
            title=f'Interactive: {year_col.title()} vs {price_col.title()}',
            labels={year_col: year_col.title(), price_col: f'{price_col.title()} ($)'},
            opacity=0.6,
            trendline="ols"  # Add trend line
        )
        fig_plotly.show()

        # Statistical summary
        print(f"\nüìà Statistical Summary:")
        print(f"Year range: {df_clean[year_col].min():.0f} - {df_clean[year_col].max():.0f}")
        print(f"Price range: ${df_clean[price_col].min():.2f} - ${df_clean[price_col].max():.2f}")
        print(f"Average price: ${df_clean[price_col].mean():.2f}")

        # Key insights
        print(f"\nüí° KEY INSIGHTS:")
        if correlation > 0.1:
            print(f"üìà Newer properties tend to have higher prices")
        elif correlation < -0.1:
            print(f"üìâ Older properties tend to have higher prices")
        else:
            print(f"üîÑ No significant relationship between construction year and price")

        print(f"üîç The correlation of {correlation:.3f} indicates a {strength.lower()} {direction} relationship")

    else:
        print("‚ö†Ô∏è Insufficient clean data for analysis after removing outliers and missing values.")

else:
    print("‚ö†Ô∏è Required columns (construction year and price) not found for this analysis.")

"""## 7. Top Hosts Analysis
**Question 5: Who are the top 10 hosts by calculated host listing count?**
"""

# Analyze top hosts by listing count
print("üëë Top Hosts Analysis:")
print("="*30)

# Find host-related columns
host_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['host', 'owner'])]
print(f"Host-related columns: {host_cols}")

# Find listing count columns
listing_count_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['listing', 'count', 'calculated'])]
print(f"Listing count columns: {listing_count_cols}")

if host_cols and listing_count_cols:
    # Try to find the best columns for analysis
    host_name_col = None
    host_id_col = None
    listing_count_col = None

    # Find host name column
    for col in host_cols:
        if 'name' in col.lower():
            host_name_col = col
            break

    # Find host ID column
    for col in host_cols:
        if 'id' in col.lower():
            host_id_col = col
            break

    # Find calculated host listing count column
    for col in listing_count_cols:
        if 'calculated' in col.lower() and 'host' in col.lower():
            listing_count_col = col
            break

    # If not found, use any listing count column
    if not listing_count_col and listing_count_cols:
        listing_count_col = listing_count_cols[0]

    # Use host name or ID for analysis
    host_col = host_name_col if host_name_col else host_id_col

    if host_col and listing_count_col:
        print(f"\nAnalyzing using:")
        print(f"Host column: {host_col}")
        print(f"Listing count column: {listing_count_col}")

        # Get top 10 hosts by listing count
        top_hosts = df.nlargest(10, listing_count_col)[[host_col, listing_count_col]]

        # Also calculate actual listing count by grouping
        actual_counts = df.groupby(host_col).size().reset_index(name='actual_listing_count')
        actual_counts = actual_counts.sort_values('actual_listing_count', ascending=False).head(10)

        print(f"\nüèÜ Top 10 Hosts by {listing_count_col}:")
        print("-" * 50)
        print(top_hosts.to_string(index=False))

        print(f"\nüìä Top 10 Hosts by Actual Listing Count:")
        print("-" * 50)
        print(actual_counts.to_string(index=False))

        # Create visualizations
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # Bar chart of calculated listing counts
        if len(top_hosts) > 0:
            top_hosts_plot = top_hosts.set_index(host_col)[listing_count_col]
            top_hosts_plot.plot(kind='bar', ax=axes[0,0], color='royalblue', edgecolor='black')
            axes[0,0].set_title(f'Top 10 Hosts by {listing_count_col.title()}')
            axes[0,0].set_ylabel('Listing Count')
            axes[0,0].tick_params(axis='x', rotation=45)

        # Bar chart of actual listing counts
        if len(actual_counts) > 0:
            actual_counts_plot = actual_counts.set_index(host_col)['actual_listing_count']
            actual_counts_plot.plot(kind='bar', ax=axes[0,1], color='forestgreen', edgecolor='black')
            axes[0,1].set_title('Top 10 Hosts by Actual Listing Count')
            axes[0,1].set_ylabel('Actual Listing Count')
            axes[0,1].tick_params(axis='x', rotation=45)

        # Horizontal bar chart for better readability
        if len(top_hosts) > 0:
            top_hosts_plot.plot(kind='barh', ax=axes[1,0], color='orange', edgecolor='black')
            axes[1,0].set_title(f'Top Hosts - {listing_count_col.title()} (Horizontal)')
            axes[1,0].set_xlabel('Listing Count')

        # Comparison of calculated vs actual counts
        if len(actual_counts) > 0 and len(top_hosts) > 0:
            # Merge data for comparison
            comparison_data = pd.merge(
                top_hosts.set_index(host_col),
                actual_counts.set_index(host_col),
                left_index=True, right_index=True, how='inner'
            ).head(5)  # Top 5 for clarity

            if len(comparison_data) > 0:
                comparison_data.plot(kind='bar', ax=axes[1,1], width=0.8)
                axes[1,1].set_title('Calculated vs Actual Listing Counts (Top 5)')
                axes[1,1].set_ylabel('Count')
                axes[1,1].tick_params(axis='x', rotation=45)
                axes[1,1].legend(['Calculated Count', 'Actual Count'])

        plt.tight_layout()
        plt.show()

        # Interactive plotly visualization
        if len(actual_counts) > 0:
            fig_plotly = px.bar(
                actual_counts.head(10),
                x=host_col,
                y='actual_listing_count',
                title='Top 10 Hosts by Listing Count (Interactive)',
                labels={host_col: 'Host', 'actual_listing_count': 'Number of Listings'},
                color='actual_listing_count',
                color_continuous_scale='Viridis'
            )
            fig_plotly.update_layout(xaxis_tickangle=-45)
            fig_plotly.show()

        # Key insights
        print(f"\nüí° KEY INSIGHTS:")
        if len(actual_counts) > 0:
            top_host = actual_counts.iloc[0]
            print(f"üèÜ Top host: '{top_host[host_col]}' with {top_host['actual_listing_count']} listings")
            print(f"üìä Total listings by top 10 hosts: {actual_counts['actual_listing_count'].sum()}")
            print(f"üìà Average listings per top host: {actual_counts['actual_listing_count'].mean():.1f}")

            # Calculate market concentration
            total_listings = len(df)
            top_10_share = (actual_counts['actual_listing_count'].sum() / total_listings) * 100
            print(f"üéØ Top 10 hosts control {top_10_share:.1f}% of all listings")

    else:
        print("‚ö†Ô∏è Could not find appropriate host and listing count columns for analysis.")
        print("Available columns:", list(df.columns))

else:
    print("‚ö†Ô∏è Required columns (host information and listing counts) not found.")

"""## 8. Host Verification and Reviews Analysis
**Question 6: Are hosts with verified identities more likely to receive positive reviews?**
"""

# Analyze host verification vs reviews
print("‚úÖ Host Verification vs Reviews Analysis:")
print("="*45)

# Find verification-related columns
verification_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['verified', 'identity', 'verification'])]
print(f"Verification-related columns: {verification_cols}")

# Find review-related columns
review_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['review', 'rating', 'score', 'star'])]
print(f"Review-related columns: {review_cols}")

if verification_cols and review_cols:
    verification_col = verification_cols[0]

    # Find the best review column
    review_score_col = None
    review_count_col = None

    for col in review_cols:
        if any(keyword in col.lower() for keyword in ['rate', 'score', 'star', 'rating']):
            review_score_col = col
            break

    for col in review_cols:
        if 'count' in col.lower() or 'number' in col.lower():
            review_count_col = col
            break

    print(f"\nUsing columns:")
    print(f"Verification: {verification_col}")
    print(f"Review score: {review_score_col}")
    print(f"Review count: {review_count_col}")

    # Analyze verification status
    verification_counts = df[verification_col].value_counts()
    print(f"\nüìä Verification Status Distribution:")
    print("-" * 40)
    print(verification_counts)

    # Create analysis dataframe
    analysis_df = df[[verification_col] + [col for col in [review_score_col, review_count_col] if col is not None]].copy()

    # Clean review data
    if review_score_col:
        if analysis_df[review_score_col].dtype == 'object':
            analysis_df[review_score_col] = pd.to_numeric(analysis_df[review_score_col], errors='coerce')

    if review_count_col:
        if analysis_df[review_count_col].dtype == 'object':
            analysis_df[review_count_col] = pd.to_numeric(analysis_df[review_count_col], errors='coerce')

    # Group by verification status and analyze reviews
    if review_score_col:
        review_by_verification = analysis_df.groupby(verification_col)[review_score_col].agg(['mean', 'median', 'std', 'count']).round(3)
        print(f"\nüìä Review Scores by Verification Status:")
        print("-" * 50)
        print(review_by_verification)

        # Statistical test (t-test) if we have two groups
        from scipy import stats
        verified_group = analysis_df[analysis_df[verification_col] == verification_counts.index[0]][review_score_col].dropna()
        unverified_group = analysis_df[analysis_df[verification_col] == verification_counts.index[1]][review_score_col].dropna()

        if len(verified_group) > 0 and len(unverified_group) > 0:
            t_stat, p_value = stats.ttest_ind(verified_group, unverified_group)
            print(f"\nüî¨ Statistical Test (t-test):")
            print(f"t-statistic: {t_stat:.4f}")
            print(f"p-value: {p_value:.6f}")

            if p_value < 0.05:
                print("‚úÖ Statistically significant difference found!")
            else:
                print("‚ùå No statistically significant difference found.")

    if review_count_col:
        count_by_verification = analysis_df.groupby(verification_col)[review_count_col].agg(['mean', 'median', 'std', 'count']).round(3)
        print(f"\nüìä Review Counts by Verification Status:")
        print("-" * 50)
        print(count_by_verification)

    # Create comprehensive visualizations
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # Verification status distribution
    verification_counts.plot(kind='bar', ax=axes[0,0], color='lightblue', edgecolor='black')
    axes[0,0].set_title('Distribution of Host Verification Status')
    axes[0,0].set_ylabel('Number of Hosts')
    axes[0,0].tick_params(axis='x', rotation=45)

    # Box plot of review scores by verification
    if review_score_col:
        analysis_df.boxplot(column=review_score_col, by=verification_col, ax=axes[0,1])
        axes[0,1].set_title(f'{review_score_col.title()} by Verification Status')
        axes[0,1].set_ylabel('Review Score')
        plt.suptitle('')  # Remove default title

    # Average review scores comparison
    if review_score_col:
        review_by_verification['mean'].plot(kind='bar', ax=axes[1,0], color='gold', edgecolor='black')
        axes[1,0].set_title('Average Review Scores by Verification Status')
        axes[1,0].set_ylabel('Average Review Score')
        axes[1,0].tick_params(axis='x', rotation=45)

    # Review count comparison
    if review_count_col:
        count_by_verification['mean'].plot(kind='bar', ax=axes[1,1], color='lightcoral', edgecolor='black')
        axes[1,1].set_title('Average Review Count by Verification Status')
        axes[1,1].set_ylabel('Average Review Count')
        axes[1,1].tick_params(axis='x', rotation=45)

    plt.tight_layout()
    plt.show()

    # Interactive plotly visualizations
    if review_score_col:
        fig_plotly = px.box(
            analysis_df,
            x=verification_col,
            y=review_score_col,
            title=f'Review Score Distribution by Verification Status',
            labels={verification_col: 'Verification Status', review_score_col: 'Review Score'}
        )
        fig_plotly.show()

    # Key insights
    print(f"\nüí° KEY INSIGHTS:")
    if review_score_col and len(review_by_verification) >= 2:
        verified_avg = review_by_verification['mean'].iloc[0]
        unverified_avg = review_by_verification['mean'].iloc[1]
        difference = verified_avg - unverified_avg

        if difference > 0:
            print(f"üìà Verified hosts have higher average reviews: {verified_avg:.3f} vs {unverified_avg:.3f}")
            print(f"‚≠ê Difference: +{difference:.3f} points")
        elif difference < 0:
            print(f"üìâ Non-verified hosts have higher average reviews: {unverified_avg:.3f} vs {verified_avg:.3f}")
            print(f"‚≠ê Difference: {abs(difference):.3f} points")
        else:
            print(f"üîÑ Similar review scores between verified and non-verified hosts")

        if 'p_value' in locals() and p_value < 0.05:
            print(f"üéØ This difference is statistically significant (p < 0.05)")
        elif 'p_value' in locals():
            print(f"‚ö†Ô∏è This difference is not statistically significant (p = {p_value:.3f})")

else:
    print("‚ö†Ô∏è Required columns (verification status and reviews) not found for this analysis.")

"""## 9. Price and Service Fee Correlation
**Question 7: Is there a correlation between the price of a listing and its service fee?**
"""

# Analyze correlation between price and service fee
print("üí∞ Price vs Service Fee Correlation Analysis:")
print("="*50)

# Find price and fee related columns
price_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['price', 'cost', 'rate'])]
fee_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['fee', 'service', 'charge'])]

print(f"Price-related columns: {price_cols}")
print(f"Fee-related columns: {fee_cols}")

if price_cols and fee_cols:
    # Select the most appropriate columns
    price_col = None
    service_fee_col = None

    # Find main price column (usually just 'price')
    for col in price_cols:
        if col.lower() in ['price', 'listing_price', 'nightly_price']:
            price_col = col
            break
    if not price_col:
        price_col = price_cols[0]

    # Find service fee column
    for col in fee_cols:
        if 'service' in col.lower():
            service_fee_col = col
            break
    if not service_fee_col and fee_cols:
        service_fee_col = fee_cols[0]

    print(f"\nUsing columns:")
    print(f"Price column: {price_col}")
    print(f"Service fee column: {service_fee_col}")

    if price_col and service_fee_col:
        # Create analysis dataframe
        correlation_df = df[[price_col, service_fee_col]].copy()

        # Clean price data
        if correlation_df[price_col].dtype == 'object':
            correlation_df[price_col] = pd.to_numeric(
                correlation_df[price_col].astype(str).str.replace('$', '').str.replace(',', ''),
                errors='coerce'
            )

        # Clean service fee data
        if correlation_df[service_fee_col].dtype == 'object':
            correlation_df[service_fee_col] = pd.to_numeric(
                correlation_df[service_fee_col].astype(str).str.replace('$', '').str.replace(',', ''),
                errors='coerce'
            )

        # Remove missing values
        correlation_df = correlation_df.dropna()

        # Remove outliers (keep data within 1st and 99th percentile)
        for col in [price_col, service_fee_col]:
            q01 = correlation_df[col].quantile(0.01)
            q99 = correlation_df[col].quantile(0.99)
            correlation_df = correlation_df[(correlation_df[col] >= q01) & (correlation_df[col] <= q99)]

        if len(correlation_df) > 0:
            # Calculate correlation
            correlation = correlation_df[price_col].corr(correlation_df[service_fee_col])

            print(f"\nüìä Correlation Analysis:")
            print(f"Sample size: {len(correlation_df)} listings")
            print(f"Correlation coefficient: {correlation:.4f}")

            # Interpret correlation strength
            if abs(correlation) < 0.1:
                strength = "Very weak"
            elif abs(correlation) < 0.3:
                strength = "Weak"
            elif abs(correlation) < 0.5:
                strength = "Moderate"
            elif abs(correlation) < 0.7:
                strength = "Strong"
            else:
                strength = "Very strong"

            direction = "positive" if correlation > 0 else "negative"
            print(f"Relationship strength: {strength} {direction} correlation")

            # Calculate R-squared
            r_squared = correlation ** 2
            print(f"R-squared: {r_squared:.4f} ({r_squared*100:.1f}% of variance explained)")

            # Statistical summary
            print(f"\nüìà Statistical Summary:")
            print(f"Price range: ${correlation_df[price_col].min():.2f} - ${correlation_df[price_col].max():.2f}")
            print(f"Service fee range: ${correlation_df[service_fee_col].min():.2f} - ${correlation_df[service_fee_col].max():.2f}")
            print(f"Average price: ${correlation_df[price_col].mean():.2f}")
            print(f"Average service fee: ${correlation_df[service_fee_col].mean():.2f}")

            # Create comprehensive visualizations
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))

            # Scatter plot
            axes[0,0].scatter(correlation_df[price_col], correlation_df[service_fee_col], alpha=0.5, color='blue')
            axes[0,0].set_xlabel(f'{price_col.title()} ($)')
            axes[0,0].set_ylabel(f'{service_fee_col.title()} ($)')
            axes[0,0].set_title(f'Scatter Plot: {price_col.title()} vs {service_fee_col.title()}')

            # Add trend line
            z = np.polyfit(correlation_df[price_col], correlation_df[service_fee_col], 1)
            p = np.poly1d(z)
            axes[0,0].plot(correlation_df[price_col], p(correlation_df[price_col]), "r--", alpha=0.8, linewidth=2)
            axes[0,0].text(0.05, 0.95, f'r = {correlation:.3f}', transform=axes[0,0].transAxes,
                          bbox=dict(boxstyle="round", facecolor='white', alpha=0.8))

            # Hexbin plot for density
            axes[0,1].hexbin(correlation_df[price_col], correlation_df[service_fee_col], gridsize=20, cmap='Blues')
            axes[0,1].set_xlabel(f'{price_col.title()} ($)')
            axes[0,1].set_ylabel(f'{service_fee_col.title()} ($)')
            axes[0,1].set_title('Density Plot: Price vs Service Fee')

            # Residual plot
            predicted = p(correlation_df[price_col])
            residuals = correlation_df[service_fee_col] - predicted
            axes[1,0].scatter(predicted, residuals, alpha=0.5, color='red')
            axes[1,0].axhline(y=0, color='black', linestyle='--')
            axes[1,0].set_xlabel('Predicted Service Fee ($)')
            axes[1,0].set_ylabel('Residuals ($)')
            axes[1,0].set_title('Residual Plot')

            # Service fee as percentage of price
            correlation_df['fee_percentage'] = (correlation_df[service_fee_col] / correlation_df[price_col]) * 100
            correlation_df['fee_percentage'].hist(bins=30, ax=axes[1,1], color='green', alpha=0.7, edgecolor='black')
            axes[1,1].set_xlabel('Service Fee as % of Price')
            axes[1,1].set_ylabel('Frequency')
            axes[1,1].set_title('Distribution of Service Fee Percentage')
            axes[1,1].axvline(correlation_df['fee_percentage'].mean(), color='red', linestyle='--',
                             label=f'Mean: {correlation_df["fee_percentage"].mean():.1f}%')
            axes[1,1].legend()

            plt.tight_layout()
            plt.show()

            # Interactive plotly scatter plot
            fig_plotly = px.scatter(
                correlation_df,
                x=price_col,
                y=service_fee_col,
                title=f'Interactive: {price_col.title()} vs {service_fee_col.title()}',
                labels={price_col: f'{price_col.title()} ($)', service_fee_col: f'{service_fee_col.title()} ($)'},
                opacity=0.6,
                trendline="ols"  # Add trend line
            )
            fig_plotly.show()

            # Service fee percentage analysis
            avg_fee_percentage = correlation_df['fee_percentage'].mean()
            median_fee_percentage = correlation_df['fee_percentage'].median()

            print(f"\nüí° KEY INSIGHTS:")
            print(f"üîç The correlation of {correlation:.3f} indicates a {strength.lower()} {direction} relationship")

            if correlation > 0.5:
                print(f"üìà Strong positive correlation: Higher prices tend to have higher service fees")
            elif correlation > 0.3:
                print(f"üìä Moderate positive correlation: Some relationship between price and service fees")
            elif correlation < -0.3:
                print(f"üìâ Negative correlation: Higher prices tend to have lower service fees")
            else:
                print(f"üîÑ Weak correlation: Limited relationship between price and service fees")

            print(f"üí∞ Average service fee: {avg_fee_percentage:.1f}% of listing price")
            print(f"üí∞ Median service fee: {median_fee_percentage:.1f}% of listing price")
            print(f"üìä R-squared: {r_squared:.3f} means {r_squared*100:.1f}% of service fee variation is explained by price")

        else:
            print("‚ö†Ô∏è Insufficient clean data for correlation analysis after removing outliers.")

    else:
        print("‚ö†Ô∏è Could not identify appropriate price and service fee columns.")

else:
    print("‚ö†Ô∏è Required columns (price and service fee) not found for this analysis.")

"""## 10. Review Rate Analysis
**Question 8: What is the average review rate number (e.g., stars) for listings, and does it vary based on neighborhood group and room type?**
"""

# Analyze review rates by neighborhood and room type
print("‚≠ê Review Rate Analysis by Neighborhood and Room Type:")
print("="*60)

# Find relevant columns
review_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['review', 'rating', 'score', 'star'])]
neighborhood_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['neighborhood', 'borough', 'area'])]
room_type_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['room', 'type', 'property'])]

print(f"Review-related columns: {review_cols}")
print(f"Neighborhood-related columns: {neighborhood_cols}")
print(f"Room type-related columns: {room_type_cols}")

# Select best columns
review_rate_col = None
for col in review_cols:
    if any(keyword in col.lower() for keyword in ['rate', 'rating', 'score', 'star']):
        review_rate_col = col
        break

neighborhood_col = neighborhood_cols[0] if neighborhood_cols else None
room_type_col = room_type_cols[0] if room_type_cols else None

print(f"\nUsing columns:")
print(f"Review rate: {review_rate_col}")
print(f"Neighborhood: {neighborhood_col}")
print(f"Room type: {room_type_col}")

if review_rate_col:
    # Create analysis dataframe
    analysis_cols = [review_rate_col]
    if neighborhood_col:
        analysis_cols.append(neighborhood_col)
    if room_type_col:
        analysis_cols.append(room_type_col)

    analysis_df = df[analysis_cols].copy()

    # Clean review rate data
    if analysis_df[review_rate_col].dtype == 'object':
        analysis_df[review_rate_col] = pd.to_numeric(analysis_df[review_rate_col], errors='coerce')

    # Remove missing values
    analysis_df = analysis_df.dropna()

    if len(analysis_df) > 0:
        # Overall review rate statistics
        overall_stats = analysis_df[review_rate_col].describe()
        print(f"\nüìä Overall Review Rate Statistics:")
        print("-" * 40)
        print(f"Count: {overall_stats['count']:.0f}")
        print(f"Mean: {overall_stats['mean']:.3f}")
        print(f"Median: {overall_stats['50%']:.3f}")
        print(f"Std Dev: {overall_stats['std']:.3f}")
        print(f"Min: {overall_stats['min']:.3f}")
        print(f"Max: {overall_stats['max']:.3f}")

        # Analysis by neighborhood
        if neighborhood_col:
            neighborhood_stats = analysis_df.groupby(neighborhood_col)[review_rate_col].agg(['mean', 'median', 'std', 'count']).round(3)
            neighborhood_stats = neighborhood_stats.sort_values('mean', ascending=False)
            print(f"\nüèòÔ∏è Review Rates by {neighborhood_col.title()}:")
            print("-" * 50)
            print(neighborhood_stats)

        # Analysis by room type
        if room_type_col:
            room_type_stats = analysis_df.groupby(room_type_col)[review_rate_col].agg(['mean', 'median', 'std', 'count']).round(3)
            room_type_stats = room_type_stats.sort_values('mean', ascending=False)
            print(f"\nüè† Review Rates by {room_type_col.title()}:")
            print("-" * 50)
            print(room_type_stats)

        # Cross-tabulation analysis
        if neighborhood_col and room_type_col:
            crosstab_mean = pd.crosstab(analysis_df[neighborhood_col], analysis_df[room_type_col],
                                       values=analysis_df[review_rate_col], aggfunc='mean').round(3)
            print(f"\nüîç Average Review Rates: {neighborhood_col.title()} vs {room_type_col.title()}:")
            print("-" * 70)
            print(crosstab_mean)

        # Create comprehensive visualizations
        num_plots = 2 + (1 if neighborhood_col else 0) + (1 if room_type_col else 0)
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # Overall distribution
        analysis_df[review_rate_col].hist(bins=30, ax=axes[0,0], color='skyblue', alpha=0.7, edgecolor='black')
        axes[0,0].axvline(analysis_df[review_rate_col].mean(), color='red', linestyle='--',
                         label=f'Mean: {analysis_df[review_rate_col].mean():.2f}')
        axes[0,0].set_xlabel(f'{review_rate_col.title()}')
        axes[0,0].set_ylabel('Frequency')
        axes[0,0].set_title(f'Distribution of {review_rate_col.title()}')
        axes[0,0].legend()

        # Box plot overall
        axes[0,1].boxplot(analysis_df[review_rate_col])
        axes[0,1].set_ylabel(f'{review_rate_col.title()}')
        axes[0,1].set_title(f'Box Plot of {review_rate_col.title()}')

        # By neighborhood
        if neighborhood_col:
            neighborhood_stats['mean'].plot(kind='bar', ax=axes[1,0], color='lightcoral', edgecolor='black')
            axes[1,0].set_title(f'Average {review_rate_col.title()} by {neighborhood_col.title()}')
            axes[1,0].set_ylabel(f'Average {review_rate_col.title()}')
            axes[1,0].tick_params(axis='x', rotation=45)

        # By room type
        if room_type_col:
            room_type_stats['mean'].plot(kind='bar', ax=axes[1,1], color='lightgreen', edgecolor='black')
            axes[1,1].set_title(f'Average {review_rate_col.title()} by {room_type_col.title()}')
            axes[1,1].set_ylabel(f'Average {review_rate_col.title()}')
            axes[1,1].tick_params(axis='x', rotation=45)

        plt.tight_layout()
        plt.show()

        # Heatmap for cross-tabulation
        if neighborhood_col and room_type_col and len(crosstab_mean) > 1:
            plt.figure(figsize=(12, 8))
            sns.heatmap(crosstab_mean, annot=True, cmap='YlOrRd', fmt='.3f', cbar_kws={'label': f'Average {review_rate_col.title()}'})
            plt.title(f'Heatmap: Average {review_rate_col.title()} by {neighborhood_col.title()} and {room_type_col.title()}')
            plt.ylabel(neighborhood_col.title())
            plt.xlabel(room_type_col.title())
            plt.xticks(rotation=45)
            plt.yticks(rotation=0)
            plt.tight_layout()
            plt.show()

        # Interactive plotly visualizations
        if neighborhood_col:
            fig_plotly = px.box(
                analysis_df,
                x=neighborhood_col,
                y=review_rate_col,
                title=f'{review_rate_col.title()} Distribution by {neighborhood_col.title()}',
                labels={neighborhood_col: neighborhood_col.title(), review_rate_col: review_rate_col.title()}
            )
            fig_plotly.update_xaxes(tickangle=45)
            fig_plotly.show()

        if room_type_col:
            fig_plotly2 = px.box(
                analysis_df,
                x=room_type_col,
                y=review_rate_col,
                title=f'{review_rate_col.title()} Distribution by {room_type_col.title()}',
                labels={room_type_col: room_type_col.title(), review_rate_col: review_rate_col.title()}
            )
            fig_plotly2.update_xaxes(tickangle=45)
            fig_plotly2.show()

        # Statistical testing (ANOVA)
        from scipy import stats

        if neighborhood_col:
            # ANOVA for neighborhoods
            neighborhood_groups = [group[review_rate_col].values for name, group in analysis_df.groupby(neighborhood_col)]
            if len(neighborhood_groups) > 1:
                f_stat, p_value = stats.f_oneway(*neighborhood_groups)
                print(f"\nüî¨ ANOVA Test for {neighborhood_col.title()}:")
                print(f"F-statistic: {f_stat:.4f}")
                print(f"p-value: {p_value:.6f}")
                if p_value < 0.05:
                    print("‚úÖ Significant differences found between neighborhoods!")
                else:
                    print("‚ùå No significant differences between neighborhoods.")

        if room_type_col:
            # ANOVA for room types
            room_type_groups = [group[review_rate_col].values for name, group in analysis_df.groupby(room_type_col)]
            if len(room_type_groups) > 1:
                f_stat, p_value = stats.f_oneway(*room_type_groups)
                print(f"\nüî¨ ANOVA Test for {room_type_col.title()}:")
                print(f"F-statistic: {f_stat:.4f}")
                print(f"p-value: {p_value:.6f}")
                if p_value < 0.05:
                    print("‚úÖ Significant differences found between room types!")
                else:
                    print("‚ùå No significant differences between room types.")

        # Key insights
        print(f"\nüí° KEY INSIGHTS:")
        print(f"‚≠ê Overall average review rate: {analysis_df[review_rate_col].mean():.3f}")

        if neighborhood_col and len(neighborhood_stats) > 0:
            best_neighborhood = neighborhood_stats.index[0]
            worst_neighborhood = neighborhood_stats.index[-1]
            print(f"üèÜ Best neighborhood: '{best_neighborhood}' ({neighborhood_stats.loc[best_neighborhood, 'mean']:.3f})")
            print(f"üîª Lowest neighborhood: '{worst_neighborhood}' ({neighborhood_stats.loc[worst_neighborhood, 'mean']:.3f})")

        if room_type_col and len(room_type_stats) > 0:
            best_room_type = room_type_stats.index[0]
            worst_room_type = room_type_stats.index[-1]
            print(f"üè† Best room type: '{best_room_type}' ({room_type_stats.loc[best_room_type, 'mean']:.3f})")
            print(f"üîª Lowest room type: '{worst_room_type}' ({room_type_stats.loc[worst_room_type, 'mean']:.3f})")

    else:
        print("‚ö†Ô∏è No valid data found after cleaning.")

else:
    print("‚ö†Ô∏è Review rate column not found for this analysis.")

"""## 11. Host Listing Count vs Availability Analysis
**Question 9: Are hosts with a higher calculated host listings count more likely to maintain higher availability throughout the year?**
"""

# Analyze relationship between host listing count and availability
print("üìä Host Listing Count vs Availability Analysis:")
print("="*55)

# Find relevant columns
host_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['host', 'owner'])]
listing_count_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['listing', 'count', 'calculated'])]
availability_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['availability', 'available', 'days'])]

print(f"Host-related columns: {host_cols}")
print(f"Listing count-related columns: {listing_count_cols}")
print(f"Availability-related columns: {availability_cols}")

# Select best columns
host_listing_count_col = None
availability_col = None

# Find calculated host listing count
for col in listing_count_cols:
    if 'calculated' in col.lower() and 'host' in col.lower():
        host_listing_count_col = col
        break

# If not found, use any listing count column
if not host_listing_count_col and listing_count_cols:
    host_listing_count_col = listing_count_cols[0]

# Find availability column
for col in availability_cols:
    if any(keyword in col.lower() for keyword in ['365', 'year', 'annual']):
        availability_col = col
        break

# If not found, use first availability column
if not availability_col and availability_cols:
    availability_col = availability_cols[0]

print(f"\nUsing columns:")
print(f"Host listing count: {host_listing_count_col}")
print(f"Availability: {availability_col}")

if host_listing_count_col and availability_col:
    # Create analysis dataframe
    analysis_df = df[[host_listing_count_col, availability_col]].copy()

    # Clean data
    for col in [host_listing_count_col, availability_col]:
        if analysis_df[col].dtype == 'object':
            analysis_df[col] = pd.to_numeric(analysis_df[col], errors='coerce')

    # Remove missing values
    analysis_df = analysis_df.dropna()

    # Remove outliers (keep data within reasonable ranges)
    # Host listing count: reasonable range 1-100
    analysis_df = analysis_df[(analysis_df[host_listing_count_col] >= 1) & (analysis_df[host_listing_count_col] <= 100)]

    # Availability: should be 0-365 days
    analysis_df = analysis_df[(analysis_df[availability_col] >= 0) & (analysis_df[availability_col] <= 365)]

    if len(analysis_df) > 0:
        # Calculate correlation
        correlation = analysis_df[host_listing_count_col].corr(analysis_df[availability_col])

        print(f"\nüìä Correlation Analysis:")
        print(f"Sample size: {len(analysis_df)} listings")
        print(f"Correlation coefficient: {correlation:.4f}")

        # Interpret correlation strength
        if abs(correlation) < 0.1:
            strength = "Very weak"
        elif abs(correlation) < 0.3:
            strength = "Weak"
        elif abs(correlation) < 0.5:
            strength = "Moderate"
        elif abs(correlation) < 0.7:
            strength = "Strong"
        else:
            strength = "Very strong"

        direction = "positive" if correlation > 0 else "negative"
        print(f"Relationship strength: {strength} {direction} correlation")

        # Group hosts by listing count categories
        analysis_df['host_category'] = pd.cut(analysis_df[host_listing_count_col],
                                            bins=[0, 1, 5, 10, 20, float('inf')],
                                            labels=['Single (1)', 'Small (2-5)', 'Medium (6-10)', 'Large (11-20)', 'Very Large (21+)'])

        # Calculate statistics by host category
        category_stats = analysis_df.groupby('host_category')[availability_col].agg(['mean', 'median', 'std', 'count']).round(2)
        print(f"\nüè† Availability by Host Size Category:")
        print("-" * 50)
        print(category_stats)

        # Overall statistics
        print(f"\nüìà Overall Statistics:")
        print(f"Average host listing count: {analysis_df[host_listing_count_col].mean():.2f}")
        print(f"Average availability: {analysis_df[availability_col].mean():.2f} days")
        print(f"Median host listing count: {analysis_df[host_listing_count_col].median():.2f}")
        print(f"Median availability: {analysis_df[availability_col].median():.2f} days")

        # Create comprehensive visualizations
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # Scatter plot
        axes[0,0].scatter(analysis_df[host_listing_count_col], analysis_df[availability_col], alpha=0.5, color='blue')
        axes[0,0].set_xlabel(f'{host_listing_count_col.title()}')
        axes[0,0].set_ylabel(f'{availability_col.title()} (days)')
        axes[0,0].set_title(f'Scatter Plot: Host Listing Count vs Availability')

        # Add trend line
        z = np.polyfit(analysis_df[host_listing_count_col], analysis_df[availability_col], 1)
        p = np.poly1d(z)
        axes[0,0].plot(analysis_df[host_listing_count_col], p(analysis_df[host_listing_count_col]), "r--", alpha=0.8, linewidth=2)
        axes[0,0].text(0.05, 0.95, f'r = {correlation:.3f}', transform=axes[0,0].transAxes,
                      bbox=dict(boxstyle="round", facecolor='white', alpha=0.8))

        # Box plot by host category
        analysis_df.boxplot(column=availability_col, by='host_category', ax=axes[0,1])
        axes[0,1].set_title('Availability Distribution by Host Category')
        axes[0,1].set_ylabel('Availability (days)')
        axes[0,1].tick_params(axis='x', rotation=45)
        plt.suptitle('')  # Remove default title

        # Bar chart of average availability by category
        category_stats['mean'].plot(kind='bar', ax=axes[1,0], color='lightgreen', edgecolor='black')
        axes[1,0].set_title('Average Availability by Host Category')
        axes[1,0].set_ylabel('Average Availability (days)')
        axes[1,0].set_xlabel('Host Category')
        axes[1,0].tick_params(axis='x', rotation=45)

        # Hexbin plot for density
        axes[1,1].hexbin(analysis_df[host_listing_count_col], analysis_df[availability_col], gridsize=20, cmap='Blues')
        axes[1,1].set_xlabel(f'{host_listing_count_col.title()}')
        axes[1,1].set_ylabel(f'{availability_col.title()} (days)')
        axes[1,1].set_title('Density Plot: Host Count vs Availability')

        plt.tight_layout()
        plt.show()

        # Interactive plotly visualizations
        fig_plotly = px.scatter(
            analysis_df,
            x=host_listing_count_col,
            y=availability_col,
            color='host_category',
            title=f'Interactive: Host Listing Count vs Availability',
            labels={host_listing_count_col: 'Host Listing Count', availability_col: 'Availability (days)'},
            opacity=0.6,
            trendline="ols"
        )
        fig_plotly.show()

        # Box plot interactive
        fig_plotly2 = px.box(
            analysis_df,
            x='host_category',
            y=availability_col,
            title='Availability Distribution by Host Category',
            labels={'host_category': 'Host Category', availability_col: 'Availability (days)'}
        )
        fig_plotly2.update_xaxes(tickangle=45)
        fig_plotly2.show()

        # Statistical testing (ANOVA)
        from scipy import stats

        category_groups = [group[availability_col].values for name, group in analysis_df.groupby('host_category')]
        if len(category_groups) > 1:
            f_stat, p_value = stats.f_oneway(*category_groups)
            print(f"\nüî¨ ANOVA Test for Host Categories:")
            print(f"F-statistic: {f_stat:.4f}")
            print(f"p-value: {p_value:.6f}")
            if p_value < 0.05:
                print("‚úÖ Significant differences found between host categories!")
            else:
                print("‚ùå No significant differences between host categories.")

        # Key insights
        print(f"\nüí° KEY INSIGHTS:")

        if correlation > 0.1:
            print(f"üìà Hosts with more listings tend to have higher availability")
            print(f"üíº This suggests professional/commercial hosts maintain better availability")
        elif correlation < -0.1:
            print(f"üìâ Hosts with more listings tend to have lower availability")
            print(f"üè† This might indicate personal use reducing availability")
        else:
            print(f"üîÑ No clear relationship between listing count and availability")

        print(f"üîç The correlation of {correlation:.3f} indicates a {strength.lower()} {direction} relationship")

        # Compare extreme categories
        if len(category_stats) >= 2:
            single_hosts_avg = category_stats.loc['Single (1)', 'mean']
            large_hosts_avg = category_stats.loc[category_stats.index[-1], 'mean']  # Largest category

            print(f"üè† Single-listing hosts average availability: {single_hosts_avg:.1f} days")
            print(f"üè¢ Large hosts average availability: {large_hosts_avg:.1f} days")
            print(f"üìä Difference: {large_hosts_avg - single_hosts_avg:.1f} days")

        # Market insights
        total_hosts = analysis_df[host_listing_count_col].nunique() if 'host' in str(host_listing_count_col).lower() else len(analysis_df)
        multi_listing_hosts = len(analysis_df[analysis_df[host_listing_count_col] > 1])

        print(f"üéØ {(multi_listing_hosts/len(analysis_df))*100:.1f}% of listings belong to hosts with multiple properties")

    else:
        print("‚ö†Ô∏è Insufficient clean data for analysis after removing outliers.")

else:
    print("‚ö†Ô∏è Required columns (host listing count and availability) not found for this analysis.")

"""## 12. Comprehensive Data Visualization Dashboard
Creating interactive dashboards and comprehensive visualizations to display key insights and trends.
"""

# Create comprehensive dashboard visualizations
print("üìä Creating Comprehensive Dashboard:")
print("="*40)

# Set up the plotting style for dashboard
plt.style.use('default')
plt.rcParams['figure.facecolor'] = 'white'
plt.rcParams['axes.facecolor'] = 'white'

# Create a large comprehensive dashboard
fig = plt.figure(figsize=(20, 24))

# Define a color palette
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', '#FF9FF3', '#54A0FF', '#5F27CD']

# Dashboard Title
fig.suptitle('üè† AIRBNB DATA ANALYSIS DASHBOARD üè†\nNew York City Listing Insights',
             fontsize=24, fontweight='bold', y=0.98)

try:
    # Find key columns for dashboard
    price_cols = [col for col in df.columns if 'price' in col.lower()]
    neighborhood_cols = [col for col in df.columns if 'neighborhood' in col.lower()]
    room_type_cols = [col for col in df.columns if 'room' in col.lower() or 'property' in col.lower()]
    review_cols = [col for col in df.columns if 'review' in col.lower()]

    price_col = price_cols[0] if price_cols else None
    neighborhood_col = neighborhood_cols[0] if neighborhood_cols else None
    room_type_col = room_type_cols[0] if room_type_cols else None
    review_col = review_cols[0] if review_cols else None

    # Row 1: Dataset Overview (3 plots)
    # Plot 1: Dataset size info
    ax1 = plt.subplot(6, 3, 1)
    dataset_info = [len(df), df.shape[1], df.isnull().sum().sum()]
    labels = ['Total Listings', 'Columns', 'Missing Values']
    bars = ax1.bar(labels, dataset_info, color=colors[:3], edgecolor='black')
    ax1.set_title('üìä Dataset Overview', fontweight='bold')
    ax1.set_ylabel('Count')
    # Add value labels on bars
    for bar, value in zip(bars, dataset_info):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(dataset_info)*0.01,
                str(value), ha='center', va='bottom', fontweight='bold')

    # Plot 2: Data types distribution
    ax2 = plt.subplot(6, 3, 2)
    dtype_counts = df.dtypes.value_counts()
    wedges, texts, autotexts = ax2.pie(dtype_counts.values, labels=dtype_counts.index,
                                      autopct='%1.1f%%', colors=colors[:len(dtype_counts)])
    ax2.set_title('üìà Data Types Distribution', fontweight='bold')

    # Plot 3: Missing values heatmap (top 10 columns)
    ax3 = plt.subplot(6, 3, 3)
    missing_data = df.isnull().sum().sort_values(ascending=False).head(10)
    if len(missing_data[missing_data > 0]) > 0:
        bars = ax3.barh(range(len(missing_data)), missing_data.values, color='red', alpha=0.7)
        ax3.set_yticks(range(len(missing_data)))
        ax3.set_yticklabels(missing_data.index, fontsize=8)
        ax3.set_title('‚ùå Top Missing Values', fontweight='bold')
        ax3.set_xlabel('Missing Count')
    else:
        ax3.text(0.5, 0.5, 'No Missing\nValues! üéâ', ha='center', va='center',
                transform=ax3.transAxes, fontsize=14, fontweight='bold')
        ax3.set_title('‚úÖ Data Quality', fontweight='bold')

    # Row 2: Neighborhood Analysis (3 plots)
    if neighborhood_col:
        # Plot 4: Neighborhood distribution
        ax4 = plt.subplot(6, 3, 4)
        neighborhood_counts = df[neighborhood_col].value_counts().head(8)
        bars = ax4.bar(range(len(neighborhood_counts)), neighborhood_counts.values,
                      color=colors[:len(neighborhood_counts)], edgecolor='black')
        ax4.set_xticks(range(len(neighborhood_counts)))
        ax4.set_xticklabels(neighborhood_counts.index, rotation=45, ha='right')
        ax4.set_title('üèòÔ∏è Top Neighborhoods by Listings', fontweight='bold')
        ax4.set_ylabel('Number of Listings')

        # Plot 5: Neighborhood pie chart
        ax5 = plt.subplot(6, 3, 5)
        top_neighborhoods = df[neighborhood_col].value_counts().head(6)
        wedges, texts, autotexts = ax5.pie(top_neighborhoods.values, labels=top_neighborhoods.index,
                                          autopct='%1.1f%%', colors=colors[:len(top_neighborhoods)])
        ax5.set_title('ü•ß Neighborhood Distribution', fontweight='bold')

        # Plot 6: Average prices by neighborhood (if price column exists)
        ax6 = plt.subplot(6, 3, 6)
        if price_col:
            # Clean price data for visualization
            df_temp = df[[neighborhood_col, price_col]].copy()
            if df_temp[price_col].dtype == 'object':
                df_temp[price_col] = pd.to_numeric(df_temp[price_col].astype(str).str.replace('$', '').str.replace(',', ''), errors='coerce')

            avg_prices = df_temp.groupby(neighborhood_col)[price_col].mean().sort_values(ascending=False).head(8)
            bars = ax6.bar(range(len(avg_prices)), avg_prices.values,
                          color='gold', alpha=0.8, edgecolor='black')
            ax6.set_xticks(range(len(avg_prices)))
            ax6.set_xticklabels(avg_prices.index, rotation=45, ha='right')
            ax6.set_title('üí∞ Average Prices by Neighborhood', fontweight='bold')
            ax6.set_ylabel('Average Price ($)')
        else:
            ax6.text(0.5, 0.5, 'Price Data\nNot Available', ha='center', va='center',
                    transform=ax6.transAxes, fontsize=12)
            ax6.set_title('üí∞ Price Analysis', fontweight='bold')
    else:
        # Fill with general info if neighborhood data not available
        for i, ax_num in enumerate([4, 5, 6]):
            ax = plt.subplot(6, 3, ax_num)
            ax.text(0.5, 0.5, f'Neighborhood\nData Not\nAvailable',
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title(f'üèòÔ∏è Neighborhood Analysis {i+1}', fontweight='bold')

    # Row 3: Property Types and Room Analysis (3 plots)
    if room_type_col:
        # Plot 7: Room type distribution
        ax7 = plt.subplot(6, 3, 7)
        room_type_counts = df[room_type_col].value_counts()
        bars = ax7.bar(range(len(room_type_counts)), room_type_counts.values,
                      color=colors[:len(room_type_counts)], edgecolor='black')
        ax7.set_xticks(range(len(room_type_counts)))
        ax7.set_xticklabels(room_type_counts.index, rotation=45, ha='right')
        ax7.set_title('üè† Property Types Distribution', fontweight='bold')
        ax7.set_ylabel('Number of Listings')

        # Plot 8: Room type pie chart
        ax8 = plt.subplot(6, 3, 8)
        wedges, texts, autotexts = ax8.pie(room_type_counts.values, labels=room_type_counts.index,
                                          autopct='%1.1f%%', colors=colors[:len(room_type_counts)])
        ax8.set_title('ü•ß Property Types %', fontweight='bold')

        # Plot 9: Room type vs price (if available)
        ax9 = plt.subplot(6, 3, 9)
        if price_col:
            df_temp = df[[room_type_col, price_col]].copy()
            if df_temp[price_col].dtype == 'object':
                df_temp[price_col] = pd.to_numeric(df_temp[price_col].astype(str).str.replace('$', '').str.replace(',', ''), errors='coerce')

            avg_prices_room = df_temp.groupby(room_type_col)[price_col].mean()
            bars = ax9.bar(range(len(avg_prices_room)), avg_prices_room.values,
                          color='lightcoral', alpha=0.8, edgecolor='black')
            ax9.set_xticks(range(len(avg_prices_room)))
            ax9.set_xticklabels(avg_prices_room.index, rotation=45, ha='right')
            ax9.set_title('üíµ Avg Price by Property Type', fontweight='bold')
            ax9.set_ylabel('Average Price ($)')
        else:
            ax9.text(0.5, 0.5, 'Price by\nProperty Type\nNot Available',
                    ha='center', va='center', transform=ax9.transAxes, fontsize=10)
            ax9.set_title('üíµ Price by Property', fontweight='bold')
    else:
        for i, ax_num in enumerate([7, 8, 9]):
            ax = plt.subplot(6, 3, ax_num)
            ax.text(0.5, 0.5, f'Property Type\nData Not\nAvailable',
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title(f'üè† Property Analysis {i+1}', fontweight='bold')

    # Row 4: Price Analysis (3 plots)
    if price_col:
        # Clean price data
        df_price = df[price_col].copy()
        if df_price.dtype == 'object':
            df_price = pd.to_numeric(df_price.astype(str).str.replace('$', '').str.replace(',', ''), errors='coerce')
        df_price = df_price.dropna()

        # Remove extreme outliers for better visualization
        q99 = df_price.quantile(0.99)
        q01 = df_price.quantile(0.01)
        df_price_clean = df_price[(df_price >= q01) & (df_price <= q99)]

        # Plot 10: Price distribution
        ax10 = plt.subplot(6, 3, 10)
        ax10.hist(df_price_clean, bins=30, color='skyblue', alpha=0.7, edgecolor='black')
        ax10.axvline(df_price_clean.mean(), color='red', linestyle='--', linewidth=2,
                    label=f'Mean: ${df_price_clean.mean():.0f}')
        ax10.axvline(df_price_clean.median(), color='green', linestyle='--', linewidth=2,
                    label=f'Median: ${df_price_clean.median():.0f}')
        ax10.set_title('üí∞ Price Distribution', fontweight='bold')
        ax10.set_xlabel('Price ($)')
        ax10.set_ylabel('Frequency')
        ax10.legend()

        # Plot 11: Price box plot
        ax11 = plt.subplot(6, 3, 11)
        box_plot = ax11.boxplot(df_price_clean, patch_artist=True)
        box_plot['boxes'][0].set_facecolor('lightgreen')
        ax11.set_title('üì¶ Price Box Plot', fontweight='bold')
        ax11.set_ylabel('Price ($)')
        ax11.set_xticklabels(['All Listings'])

        # Plot 12: Price statistics
        ax12 = plt.subplot(6, 3, 12)
        price_stats = [df_price_clean.min(), df_price_clean.quantile(0.25),
                      df_price_clean.median(), df_price_clean.quantile(0.75), df_price_clean.max()]
        stat_labels = ['Min', 'Q1', 'Median', 'Q3', 'Max']
        bars = ax12.bar(stat_labels, price_stats, color='orange', alpha=0.8, edgecolor='black')
        ax12.set_title('üìä Price Statistics', fontweight='bold')
        ax12.set_ylabel('Price ($)')

        # Add value labels on bars
        for bar, value in zip(bars, price_stats):
            ax12.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(price_stats)*0.01,
                     f'${value:.0f}', ha='center', va='bottom', fontweight='bold')
    else:
        for i, ax_num in enumerate([10, 11, 12]):
            ax = plt.subplot(6, 3, ax_num)
            ax.text(0.5, 0.5, f'Price Data\nNot Available',
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title(f'üí∞ Price Analysis {i+1}', fontweight='bold')

    # Row 5: Review Analysis (3 plots)
    if review_col:
        review_data = df[review_col].copy()
        if review_data.dtype == 'object':
            review_data = pd.to_numeric(review_data, errors='coerce')
        review_data = review_data.dropna()

        # Plot 13: Review distribution
        ax13 = plt.subplot(6, 3, 13)
        ax13.hist(review_data, bins=20, color='plum', alpha=0.7, edgecolor='black')
        ax13.axvline(review_data.mean(), color='red', linestyle='--', linewidth=2,
                    label=f'Mean: {review_data.mean():.2f}')
        ax13.set_title('‚≠ê Review Scores Distribution', fontweight='bold')
        ax13.set_xlabel('Review Score')
        ax13.set_ylabel('Frequency')
        ax13.legend()

        # Plot 14: Review statistics
        ax14 = plt.subplot(6, 3, 14)
        review_stats = [review_data.count(), review_data.mean(), review_data.median(), review_data.std()]
        stat_labels = ['Count', 'Mean', 'Median', 'Std Dev']
        bars = ax14.bar(stat_labels, review_stats, color='lightseagreen', alpha=0.8, edgecolor='black')
        ax14.set_title('üìä Review Statistics', fontweight='bold')
        ax14.set_ylabel('Value')

        # Plot 15: Review categories
        ax15 = plt.subplot(6, 3, 15)
        # Create review categories
        if review_data.max() <= 5:  # Assuming 5-star rating system
            review_bins = [0, 2, 3, 4, 5]
            review_labels = ['Poor (0-2)', 'Fair (2-3)', 'Good (3-4)', 'Excellent (4-5)']
        else:  # Assuming different rating system
            review_bins = [review_data.min(), review_data.quantile(0.25),
                          review_data.quantile(0.5), review_data.quantile(0.75), review_data.max()]
            review_labels = ['Low', 'Medium-Low', 'Medium-High', 'High']

        review_categories = pd.cut(review_data, bins=review_bins, labels=review_labels, include_lowest=True)
        category_counts = review_categories.value_counts()

        wedges, texts, autotexts = ax15.pie(category_counts.values, labels=category_counts.index,
                                           autopct='%1.1f%%', colors=colors[:len(category_counts)])
        ax15.set_title('ü•ß Review Categories', fontweight='bold')
    else:
        for i, ax_num in enumerate([13, 14, 15]):
            ax = plt.subplot(6, 3, ax_num)
            ax.text(0.5, 0.5, f'Review Data\nNot Available',
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title(f'‚≠ê Review Analysis {i+1}', fontweight='bold')

    # Row 6: Summary and Key Metrics (3 plots)
    # Plot 16: Key metrics summary
    ax16 = plt.subplot(6, 3, 16)
    metrics = ['Total Listings', 'Neighborhoods', 'Property Types', 'Avg Reviews']
    values = [
        len(df),
        df[neighborhood_col].nunique() if neighborhood_col else 0,
        df[room_type_col].nunique() if room_type_col else 0,
        df[review_col].mean() if review_col and pd.api.types.is_numeric_dtype(df[review_col]) else 0
    ]

    bars = ax16.bar(metrics, values, color=colors[:4], edgecolor='black')
    ax16.set_title('üìà Key Metrics Summary', fontweight='bold')
    ax16.set_ylabel('Count/Value')
    plt.setp(ax16.get_xticklabels(), rotation=45, ha='right')

    # Add value labels
    for bar, value in zip(bars, values):
        label = f'{value:.0f}' if value >= 1 else f'{value:.2f}'
        ax16.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,
                 label, ha='center', va='bottom', fontweight='bold')

    # Plot 17: Data completeness
    ax17 = plt.subplot(6, 3, 17)
    completeness = ((len(df) - df.isnull().sum()) / len(df) * 100).sort_values(ascending=True)
    top_incomplete = completeness.head(10)  # Show 10 most incomplete columns

    bars = ax17.barh(range(len(top_incomplete)), top_incomplete.values,
                    color='lightcoral', edgecolor='black')
    ax17.set_yticks(range(len(top_incomplete)))
    ax17.set_yticklabels([col[:15] + '...' if len(col) > 15 else col for col in top_incomplete.index], fontsize=8)
    ax17.set_title('üìä Data Completeness %', fontweight='bold')
    ax17.set_xlabel('Completeness (%)')

    # Plot 18: Final insights
    ax18 = plt.subplot(6, 3, 18)
    ax18.axis('off')

    # Create a text summary
    insights_text = f"""
    üéØ KEY INSIGHTS SUMMARY

    üìä Dataset Size: {len(df):,} listings

    üèòÔ∏è Geographic Spread:
    {df[neighborhood_col].nunique() if neighborhood_col else 'N/A'} neighborhoods

    üè† Property Variety:
    {df[room_type_col].nunique() if room_type_col else 'N/A'} property types

    üí∞ Price Range:
    ${df[price_col].min():.0f} - ${df[price_col].max():.0f}
    """ if price_col and pd.api.types.is_numeric_dtype(df[price_col]) else """
    üéØ KEY INSIGHTS SUMMARY

    üìä Dataset Size: {:,} listings

    üèòÔ∏è Neighborhoods: {}

    üè† Property Types: {}

    üìà Analysis Complete!
    """.format(
        len(df),
        df[neighborhood_col].nunique() if neighborhood_col else 'N/A',
        df[room_type_col].nunique() if room_type_col else 'N/A'
    )

    ax18.text(0.1, 0.5, insights_text, transform=ax18.transAxes, fontsize=11,
             verticalalignment='center', bbox=dict(boxstyle="round,pad=0.3", facecolor='lightblue', alpha=0.7))

except Exception as e:
    print(f"‚ö†Ô∏è Error creating dashboard: {e}")
    print("Creating simplified dashboard...")

    # Simplified dashboard if there are issues
    ax_simple = plt.subplot(1, 1, 1)
    ax_simple.text(0.5, 0.5, f'üìä AIRBNB ANALYSIS DASHBOARD\n\n'
                             f'Dataset loaded successfully!\n'
                             f'Shape: {df.shape}\n'
                             f'Columns: {len(df.columns)}\n\n'
                             f'‚úÖ Ready for analysis!',
                  ha='center', va='center', transform=ax_simple.transAxes,
                  fontsize=16, bbox=dict(boxstyle="round,pad=0.5", facecolor='lightgreen', alpha=0.7))
    ax_simple.set_title('Airbnb Data Analysis Dashboard', fontsize=20, fontweight='bold')
    ax_simple.axis('off')

plt.tight_layout()
plt.subplots_adjust(top=0.95, hspace=0.4, wspace=0.3)
plt.show()

print("‚úÖ Comprehensive dashboard created successfully!")
print("üé® Dashboard includes: Dataset overview, neighborhood analysis, property types, pricing, reviews, and key metrics")

"""## 13. Statistical Analysis and Business Insights
Comprehensive statistical analysis and data-driven recommendations for stakeholders.
"""

# Statistical Analysis and Business Insights
print("üîç COMPREHENSIVE STATISTICAL ANALYSIS & BUSINESS INSIGHTS")
print("="*70)

# Generate comprehensive insights based on our analysis
insights = {
    "dataset_overview": {},
    "market_analysis": {},
    "pricing_insights": {},
    "host_performance": {},
    "guest_satisfaction": {},
    "recommendations": {}
}

# Dataset Overview Insights
insights["dataset_overview"] = {
    "total_listings": len(df),
    "total_columns": df.shape[1],
    "data_quality": f"{((df.count().sum() / (len(df) * len(df.columns))) * 100):.1f}% complete",
    "geographic_coverage": df[[col for col in df.columns if 'neighborhood' in col.lower()]].iloc[:, 0].nunique() if any('neighborhood' in col.lower() for col in df.columns) else "N/A",
    "property_diversity": df[[col for col in df.columns if 'room' in col.lower() or 'property' in col.lower()]].iloc[:, 0].nunique() if any('room' in col.lower() or 'property' in col.lower() for col in df.columns) else "N/A"
}

print("üìä DATASET OVERVIEW INSIGHTS:")
print("-" * 40)
for key, value in insights["dataset_overview"].items():
    print(f"‚Ä¢ {key.replace('_', ' ').title()}: {value}")

# Market Analysis Insights
try:
    neighborhood_cols = [col for col in df.columns if 'neighborhood' in col.lower()]
    if neighborhood_cols:
        neighborhood_col = neighborhood_cols[0]
        top_neighborhoods = df[neighborhood_col].value_counts().head(3)
        market_concentration = (top_neighborhoods.sum() / len(df)) * 100

        insights["market_analysis"] = {
            "market_leader": f"{top_neighborhoods.index[0]} ({top_neighborhoods.iloc[0]} listings)",
            "market_concentration": f"Top 3 neighborhoods control {market_concentration:.1f}% of listings",
            "geographic_diversity": f"Listings spread across {df[neighborhood_col].nunique()} neighborhoods",
            "competition_level": "High" if df[neighborhood_col].nunique() > 20 else "Moderate" if df[neighborhood_col].nunique() > 10 else "Low"
        }

        print(f"\nüèòÔ∏è MARKET ANALYSIS INSIGHTS:")
        print("-" * 40)
        for key, value in insights["market_analysis"].items():
            print(f"‚Ä¢ {key.replace('_', ' ').title()}: {value}")
except Exception as e:
    print(f"\n‚ö†Ô∏è Market analysis limited due to data structure: {e}")

# Pricing Insights
try:
    price_cols = [col for col in df.columns if 'price' in col.lower()]
    if price_cols:
        price_col = price_cols[0]
        price_data = df[price_col].copy()

        # Clean price data
        if price_data.dtype == 'object':
            price_data = pd.to_numeric(price_data.astype(str).str.replace('$', '').str.replace(',', ''), errors='coerce')

        price_data = price_data.dropna()

        if len(price_data) > 0:
            q25, q50, q75 = price_data.quantile([0.25, 0.5, 0.75])

            insights["pricing_insights"] = {
                "average_price": f"${price_data.mean():.2f}",
                "median_price": f"${q50:.2f}",
                "price_range": f"${price_data.min():.2f} - ${price_data.max():.2f}",
                "market_segments": f"Budget (<${q25:.0f}), Mid-range (${q25:.0f}-${q75:.0f}), Premium (>${q75:.0f})",
                "price_volatility": f"Standard deviation: ${price_data.std():.2f}",
                "pricing_opportunity": "High variance suggests pricing optimization potential"
            }

            print(f"\nüí∞ PRICING INSIGHTS:")
            print("-" * 40)
            for key, value in insights["pricing_insights"].items():
                print(f"‚Ä¢ {key.replace('_', ' ').title()}: {value}")
except Exception as e:
    print(f"\n‚ö†Ô∏è Pricing analysis limited: {e}")

# Host Performance Insights
try:
    host_cols = [col for col in df.columns if 'host' in col.lower()]
    listing_count_cols = [col for col in df.columns if 'listing' in col.lower() and 'count' in col.lower()]

    if host_cols and listing_count_cols:
        host_col = [col for col in host_cols if 'name' in col.lower() or 'id' in col.lower()][0]
        listing_count_col = listing_count_cols[0]

        # Calculate host performance metrics
        host_stats = df.groupby(host_col).size().reset_index(name='actual_listings')
        multi_listing_hosts = len(host_stats[host_stats['actual_listings'] > 1])
        total_hosts = len(host_stats)

        insights["host_performance"] = {
            "total_hosts": total_hosts,
            "multi_listing_hosts": f"{multi_listing_hosts} ({(multi_listing_hosts/total_hosts)*100:.1f}%)",
            "average_listings_per_host": f"{host_stats['actual_listings'].mean():.2f}",
            "max_listings_single_host": host_stats['actual_listings'].max(),
            "host_market_type": "Professional-heavy" if (multi_listing_hosts/total_hosts) > 0.3 else "Individual-heavy"
        }

        print(f"\nüëë HOST PERFORMANCE INSIGHTS:")
        print("-" * 40)
        for key, value in insights["host_performance"].items():
            print(f"‚Ä¢ {key.replace('_', ' ').title()}: {value}")
except Exception as e:
    print(f"\n‚ö†Ô∏è Host analysis limited: {e}")

# Guest Satisfaction Insights
try:
    review_cols = [col for col in df.columns if 'review' in col.lower()]
    if review_cols:
        review_col = [col for col in review_cols if any(keyword in col.lower() for keyword in ['rate', 'score', 'rating'])][0] if any(any(keyword in col.lower() for keyword in ['rate', 'score', 'rating']) for col in review_cols) else review_cols[0]

        review_data = df[review_col].copy()
        if review_data.dtype == 'object':
            review_data = pd.to_numeric(review_data, errors='coerce')

        review_data = review_data.dropna()

        if len(review_data) > 0:
            avg_rating = review_data.mean()
            satisfaction_level = "Excellent" if avg_rating >= 4.5 else "Good" if avg_rating >= 4.0 else "Fair" if avg_rating >= 3.5 else "Poor"

            insights["guest_satisfaction"] = {
                "average_rating": f"{avg_rating:.2f}",
                "satisfaction_level": satisfaction_level,
                "review_coverage": f"{len(review_data)/len(df)*100:.1f}% of listings have reviews",
                "rating_distribution": f"Std dev: {review_data.std():.2f}",
                "guest_experience": "Consistently positive" if review_data.std() < 0.5 else "Mixed experiences"
            }

            print(f"\n‚≠ê GUEST SATISFACTION INSIGHTS:")
            print("-" * 40)
            for key, value in insights["guest_satisfaction"].items():
                print(f"‚Ä¢ {key.replace('_', ' ').title()}: {value}")
except Exception as e:
    print(f"\n‚ö†Ô∏è Guest satisfaction analysis limited: {e}")

print("\n" + "="*70)
print("üéØ STRATEGIC BUSINESS RECOMMENDATIONS")
print("="*70)

# Generate actionable recommendations
recommendations = [
    {
        "category": "üèòÔ∏è MARKET EXPANSION",
        "recommendations": [
            "Target underserved neighborhoods with high demand potential",
            "Analyze seasonal trends to optimize listing distribution",
            "Consider market saturation in top neighborhoods",
            "Explore emerging neighborhoods for early market entry"
        ]
    },
    {
        "category": "üí∞ PRICING OPTIMIZATION",
        "recommendations": [
            "Implement dynamic pricing based on neighborhood demand",
            "Create tiered pricing strategy for different property types",
            "Monitor competitor pricing in high-demand areas",
            "Offer seasonal pricing adjustments for better occupancy"
        ]
    },
    {
        "category": "üëë HOST DEVELOPMENT",
        "recommendations": [
            "Provide training programs for new hosts",
            "Create incentive programs for high-performing hosts",
            "Develop tools for multi-listing host management",
            "Implement host verification programs for trust building"
        ]
    },
    {
        "category": "‚≠ê GUEST EXPERIENCE",
        "recommendations": [
            "Focus on consistent service quality across all listings",
            "Implement guest feedback loop for continuous improvement",
            "Create standards for property amenities and cleanliness",
            "Develop mobile app features for enhanced user experience"
        ]
    },
    {
        "category": "üìä DATA & ANALYTICS",
        "recommendations": [
            "Implement real-time market analytics dashboard",
            "Create predictive models for demand forecasting",
            "Develop automated pricing recommendation system",
            "Build guest preference analysis for personalization"
        ]
    }
]

for rec in recommendations:
    print(f"\n{rec['category']}:")
    print("-" * 50)
    for i, recommendation in enumerate(rec['recommendations'], 1):
        print(f"{i}. {recommendation}")

print("\n" + "="*70)
print("üìà KEY SUCCESS METRICS TO MONITOR")
print("="*70)

success_metrics = [
    "üìä Market Share: Track listings by neighborhood and property type",
    "üí∞ Revenue per Listing: Monitor average pricing and occupancy rates",
    "üëë Host Retention: Measure host satisfaction and listing longevity",
    "‚≠ê Guest Satisfaction: Track review scores and repeat bookings",
    "üèòÔ∏è Geographic Expansion: Monitor new market penetration",
    "üîÑ Listing Utilization: Analyze availability and booking patterns",
    "üí° Innovation Adoption: Track new feature usage and feedback",
    "üéØ Competitive Position: Benchmark against market competitors"
]

for i, metric in enumerate(success_metrics, 1):
    print(f"{i}. {metric}")

print("\n" + "="*70)
print("üéä ANALYSIS COMPLETE - READY FOR STRATEGIC IMPLEMENTATION! üéä")
print("="*70)

"""## üìã Executive Summary

### Project Overview
This comprehensive analysis of New York City Airbnb data provides valuable insights into the short-term rental market dynamics, pricing strategies, host performance patterns, and guest satisfaction metrics. The analysis addresses nine key research questions and delivers actionable recommendations for stakeholders.

### Key Findings Summary

**üìä Dataset Insights:**
- Comprehensive dataset with multiple property types and neighborhood coverage
- High data quality enabling robust statistical analysis
- Geographic diversity across NYC's major boroughs

**üèòÔ∏è Market Dynamics:**
- Clear neighborhood-based market segmentation
- Varying demand patterns across different areas
- Opportunity for strategic market expansion

**üí∞ Pricing Intelligence:**
- Significant price variations across neighborhoods and property types
- Dynamic pricing opportunities based on location and amenities
- Market segmentation potential (budget, mid-range, premium)

**üëë Host Ecosystem:**
- Mix of individual and professional hosts
- Performance variations based on listing portfolio size
- Verification impact on guest trust and bookings

**‚≠ê Guest Experience:**
- Generally positive satisfaction levels
- Review patterns vary by location and property type
- Service quality consistency opportunities

### Strategic Value
This analysis provides a data-driven foundation for:
- **Hosts:** Optimizing pricing and improving listing performance
- **Airbnb Platform:** Enhancing market strategy and user experience
- **Investors:** Understanding market opportunities and risks
- **Policymakers:** Analyzing short-term rental market impacts

### Next Steps
1. Implement recommended pricing strategies
2. Develop host support programs
3. Enhance guest experience initiatives
4. Monitor key performance metrics
5. Expand analysis with real-time data integration

---

*This analysis demonstrates the power of data science in understanding complex marketplace dynamics and driving strategic business decisions.*
"""